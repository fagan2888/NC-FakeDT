{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_pd = pd.read_csv(\"D://Git//natural-computing//GAforDonaldTrumpTweets//get_tweets//realDonaldTrump_tweets.csv\", delimiter='|')\n",
    "tweets = []\n",
    "tweets = tweets_pd.values\n",
    "tweets = tweets[:,1]\n",
    "\n",
    "\n",
    "list_of_words = []\n",
    "counts_of_words = []\n",
    "list_of_symbols = []\n",
    "counts_of_symbols = []\n",
    "list_of_hashtags = []\n",
    "counts_of_hashtags = []\n",
    "list_of_cites = []\n",
    "counts_of_cites = []\n",
    "\n",
    "\n",
    "\n",
    "alphabet = [\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\",\"i\",\"j\",\"k\",\"l\",\"m\",\"n\",\"o\",\"p\",\"q\",\"r\",\"s\",\"t\",\"u\",\"v\",\"w\",\"x\",\"y\",\"z\"]\n",
    "symbols = [\",\",\".\",\":\",\";\",\"-\",\"_\",\"!\",\"ยง\",\"$\",\"%\",\"&\",\"/\",\"(\",\")\",\"{\",\"}\",\"=\",\"?\",\"^\",\"'\", \"<\",\">\",\"|\"]\n",
    "numbers = [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"]\n",
    "           \n",
    "\n",
    "for tweet in tweets:\n",
    "    tweet = tweet[2:]\n",
    "    elements = tweet.split()\n",
    "    \n",
    "    for e in elements:\n",
    "        if e[0] == \"@\":\n",
    "            \n",
    "            if \".\\\\\" in e:\n",
    "                index = e.index(\".\\\\\")\n",
    "                string = \"\"\n",
    "                for i in range(index):\n",
    "                    string+=e[i]\n",
    "                e = string\n",
    "\n",
    "            if \"\\\\\" in e:\n",
    "                index = e.index(\"\\\\\")\n",
    "                string = \"\"\n",
    "                for i in range(index):\n",
    "                    string+=e[i]\n",
    "                e = string\n",
    "            \n",
    "            if e not in list_of_cites:\n",
    "                list_of_cites.append(e)\n",
    "                counts_of_cites.append(1)\n",
    "            else:\n",
    "                counts_of_cites[list_of_cites.index(e)]+=1\n",
    "            \n",
    "        if e[0]== \"#\":\n",
    "            \n",
    "            if \".\\\\\" in e:\n",
    "                index = e.index(\".\\\\\")\n",
    "                string = \"\"\n",
    "                for i in range(index):\n",
    "                    string+=e[i]\n",
    "                e = string\n",
    "\n",
    "            if \"\\\\\" in e:\n",
    "                index = e.index(\"\\\\\")\n",
    "                string = \"\"\n",
    "                for i in range(index):\n",
    "                    string+=e[i]\n",
    "                e = string\n",
    "                    \n",
    "            if e not in list_of_hashtags:\n",
    "                list_of_hashtags.append(e)\n",
    "                counts_of_hashtags.append(1)\n",
    "            else:\n",
    "                counts_of_hashtags[list_of_hashtags.index(e)]+=1\n",
    "                \n",
    "        if e[0] in symbols or e[0] in numbers:\n",
    "            s = \"\"\n",
    "\n",
    "            for index in range(len(e)):\n",
    "                if e[0] in symbols or e[0] in numbers:\n",
    "                    s+= e[0]\n",
    "                    e = e.replace(e[0],\"\",1)\n",
    "\n",
    "\n",
    "            if s not in list_of_symbols and s is not \"\":\n",
    "                list_of_symbols.append(s)\n",
    "                counts_of_symbols.append(1)\n",
    "            elif s is not \"\":\n",
    "                counts_of_symbols[list_of_symbols.index(s)]+=1\n",
    "                \n",
    "        if len(e)>0:      \n",
    "            if e[0] in alphabet:\n",
    "                s = \"\"\n",
    "                while e[len(e)-1] in symbols or e[len(e)-1] in numbers:\n",
    "                    s+=e[len(e)-1]\n",
    "                    e = e.replace(e[len(e)-1], \"\",1)\n",
    "\n",
    "                if s not in list_of_symbols and s is not \"\":\n",
    "                    list_of_symbols.append(s)\n",
    "                    counts_of_symbols.append(1)\n",
    "                elif s is not \"\":\n",
    "                    counts_of_symbols[list_of_symbols.index(s)]+=1\n",
    "\n",
    "                if \".\\\\\" in e:\n",
    "                    index = e.index(\".\\\\\")\n",
    "                    string = \"\"\n",
    "                    for i in range(index):\n",
    "                        string+=e[i]\n",
    "                    e = string\n",
    "                \n",
    "                if \"\\\\\" in e:\n",
    "                    index = e.index(\"\\\\\")\n",
    "                    string = \"\"\n",
    "                    for i in range(index):\n",
    "                        string+=e[i]\n",
    "                    e = string\n",
    "  \n",
    "  \n",
    "                \n",
    "                if e not in list_of_words:\n",
    "                    list_of_words.append(e)\n",
    "                    counts_of_words.append(1)\n",
    "                else:\n",
    "                    counts_of_words[list_of_words.index(e)]+=1\n",
    "              \n",
    "              \n",
    "#print([list_of_symbols, counts_of_symbols])                   \n",
    "#print([list_of_words, counts_of_words])\n",
    "#print([list_of_cites, counts_of_cites])\n",
    "#print(list_of_hashtags, counts_of_hashtags)\n",
    "\n",
    "output = [[list_of_symbols, counts_of_symbols],[list_of_words, counts_of_words],[list_of_cites, counts_of_cites],[list_of_hashtags, counts_of_hashtags]]\n",
    "df = pd.DataFrame(output)\n",
    "df.to_csv(\"dictionary.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup(word):\n",
    "    if word in list_of_words:\n",
    "        index = list_of_words.index(word)\n",
    "\n",
    "        counter = counts_of_words[index]\n",
    "        print(\"you is found {} times in words\".format(counter))\n",
    "\n",
    "    if word in list_of_symbols:\n",
    "        index = list_of_symbols.index(word)\n",
    "\n",
    "        counter = counts_of_symbols[index]\n",
    "        print(\"you is found {} times in symbols\".format(counter))\n",
    "        \n",
    "    \n",
    "    if word in list_of_cites:\n",
    "        index = list_of_cites.index(word)\n",
    "\n",
    "        counter = counts_of_cites[index]\n",
    "        print(\"you is found {} times in cites\".format(counter))\n",
    "        \n",
    "    \n",
    "    if word in list_of_hashtags:\n",
    "        index = list_of_hashtags.index(word)\n",
    "\n",
    "        counter = counts_of_hashtags[index]\n",
    "        print(\"you is found {} times in hashtags\".format(counter))\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you is found 3288 times in symbols\n"
     ]
    }
   ],
   "source": [
    "lookup(\"!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of words 7729\n"
     ]
    }
   ],
   "source": [
    "print(\"number of words {}\".format(len(list_of_cites)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
